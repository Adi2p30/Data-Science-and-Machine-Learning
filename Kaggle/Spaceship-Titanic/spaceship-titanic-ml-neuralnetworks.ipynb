{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://www.kaggle.com/adityapachpande/spaceship-titanic-ml-neuralnetworks\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom sklearn.metrics import accuracy_score\nimport sklearn\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:03.732809Z","iopub.execute_input":"2022-10-14T01:38:03.733373Z","iopub.status.idle":"2022-10-14T01:38:03.759851Z","shell.execute_reply.started":"2022-10-14T01:38:03.733316Z","shell.execute_reply":"2022-10-14T01:38:03.758573Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:03.763184Z","iopub.execute_input":"2022-10-14T01:38:03.763753Z","iopub.status.idle":"2022-10-14T01:38:03.814855Z","shell.execute_reply.started":"2022-10-14T01:38:03.763700Z","shell.execute_reply":"2022-10-14T01:38:03.813579Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"target = train['Transported']\ntrain = train.drop(['PassengerId','Name','Transported'], axis=1)\ntest = test.drop(['PassengerId','Name'], axis=1)\n\ncat_columns = train.dtypes[(train.dtypes == \"object\") == True].index.tolist()\nfor col in cat_columns:\n    if col != 'Cabin':\n        train[col] = train[col].fillna(f'None{col}')\ntrain['Cabin'] = train['Cabin'].fillna(train['Cabin'].mode()[0])\n\nnum_columns = train.dtypes[(train.dtypes != \"object\") == True].index.tolist()\nfor col in num_columns:\n    train[col] = train[col].fillna(train[col].median())\n    \ncat_columns = test.dtypes[(test.dtypes == \"object\") == True].index.tolist()\nfor col in cat_columns:\n    if col != 'Cabin':\n        test[col] = test[col].fillna(f'None{col}')\ntest['Cabin'] = test['Cabin'].fillna(test['Cabin'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:03.816902Z","iopub.execute_input":"2022-10-14T01:38:03.817433Z","iopub.status.idle":"2022-10-14T01:38:03.857316Z","shell.execute_reply.started":"2022-10-14T01:38:03.817381Z","shell.execute_reply":"2022-10-14T01:38:03.855902Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"num_columns = test.dtypes[(test.dtypes != \"object\") == True].index.tolist()\nfor col in num_columns:\n    test[col] = test[col].fillna(test[col].median())\n\ntarget[target == False] = 0\ntarget[target == True] = 1\n\ntrain = pd.concat((train, pd.get_dummies(train[['HomePlanet', 'CryoSleep', 'Destination', 'VIP']])), axis=1)\ntrain = train.drop(['HomePlanet', 'CryoSleep', 'Destination', 'VIP'],axis=1)\ntest = pd.concat((test, pd.get_dummies(test[['HomePlanet', 'CryoSleep', 'Destination', 'VIP']])), axis=1)\ntest = test.drop(['HomePlanet', 'CryoSleep', 'Destination', 'VIP'],axis=1)\n\ntrain = train.drop(train['Cabin'][train['Cabin'] == 'NoneCabin'].index, axis=0)\ntest = test.drop(test['Cabin'][test['Cabin'] == 'NoneCabin'].index, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:03.859760Z","iopub.execute_input":"2022-10-14T01:38:03.860158Z","iopub.status.idle":"2022-10-14T01:38:03.916247Z","shell.execute_reply.started":"2022-10-14T01:38:03.860123Z","shell.execute_reply":"2022-10-14T01:38:03.914827Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"first, sec, thrd = [], [], []\nmem = []\nfor i in range(train['Cabin'].shape[0]):\n    mem = train['Cabin'].iloc[i].split('/')\n    first.append(mem[0])\n    sec.append(mem[1])\n    thrd.append(mem[2])\nfirst = pd.Series(first)\nfirst.index = train['Cabin'].index\nsec = pd.Series(sec)\nsec.index = train['Cabin'].index\nthrd = pd.Series(thrd) \nthrd.index = train['Cabin'].index\ntrain['CabinClass'] = first\ntrain['CabinNumber'] = sec\ntrain['CabinSeat'] = thrd\n\nfirst, sec, thrd = [], [], []\nmem = []\nfor i in range(test['Cabin'].shape[0]):\n    mem = test['Cabin'].iloc[i].split('/')\n    first.append(mem[0])\n    sec.append(mem[1])\n    thrd.append(mem[2])\nfirst = pd.Series(first)\nfirst.index = test['Cabin'].index\nsec = pd.Series(sec)\nsec.index = test['Cabin'].index\nthrd = pd.Series(thrd) \nthrd.index = test['Cabin'].index\ntest['CabinClass'] = first\ntest['CabinNumber'] = sec\ntest['CabinSeat'] = thrd\n\ntrain = train.drop('Cabin',axis=1)\ntest = test.drop('Cabin',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:03.918146Z","iopub.execute_input":"2022-10-14T01:38:03.918563Z","iopub.status.idle":"2022-10-14T01:38:04.089936Z","shell.execute_reply.started":"2022-10-14T01:38:03.918527Z","shell.execute_reply":"2022-10-14T01:38:04.088183Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test.dtypes[(test.dtypes == \"object\") == True].index.tolist()\ntest.dtypes[(test.dtypes != \"object\") == True].index.tolist() == train.dtypes[(train.dtypes != \"object\") == True].index.tolist()\n\ntrain = pd.concat((train, pd.get_dummies(train['CabinClass'])), axis=1)\ntrain = pd.concat((train, pd.get_dummies(train['CabinSeat'])), axis=1)\ntrain = train.drop(['CabinClass','CabinSeat'],axis=1)\n\ntest = pd.concat((test, pd.get_dummies(test['CabinClass'])), axis=1)\ntest = pd.concat((test, pd.get_dummies(test['CabinSeat'])), axis=1)\ntest = test.drop(['CabinClass','CabinSeat'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:04.095839Z","iopub.execute_input":"2022-10-14T01:38:04.096670Z","iopub.status.idle":"2022-10-14T01:38:04.130868Z","shell.execute_reply.started":"2022-10-14T01:38:04.096616Z","shell.execute_reply":"2022-10-14T01:38:04.129400Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train.columns\ntest.columns","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:04.132440Z","iopub.execute_input":"2022-10-14T01:38:04.132817Z","iopub.status.idle":"2022-10-14T01:38:04.142618Z","shell.execute_reply.started":"2022-10-14T01:38:04.132785Z","shell.execute_reply":"2022-10-14T01:38:04.141049Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n       'HomePlanet_Earth', 'HomePlanet_Europa', 'HomePlanet_Mars',\n       'HomePlanet_NoneHomePlanet', 'CryoSleep_False', 'CryoSleep_True',\n       'CryoSleep_NoneCryoSleep', 'Destination_55 Cancri e',\n       'Destination_NoneDestination', 'Destination_PSO J318.5-22',\n       'Destination_TRAPPIST-1e', 'VIP_False', 'VIP_True', 'VIP_NoneVIP',\n       'CabinNumber', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'P', 'S'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"train = train.astype('float64')\ntest = test.astype('float64')\ntarget = target.astype('float64')\n\nlst_for_scale = []\nfor col in train.columns:\n    if len(train[col].value_counts()) != 2:\n        lst_for_scale.append(col)\n\n\n\nscaler = StandardScaler()\nscaled_train = scaler.fit_transform(train[lst_for_scale])\nscaled_test = scaler.transform(test[lst_for_scale])\nscaled_train = pd.DataFrame(scaled_train)\n\nfor i in range(0,7):\n    scaled_train = scaled_train.rename(columns={i:scaler.feature_names_in_[i]})\n    \ncopy_train = train.drop(scaler.feature_names_in_,axis=1).copy()\ntrain_final = pd.concat((scaled_train, copy_train), axis=1)\nscaled_test = pd.DataFrame(scaled_test)\n\nfor i in range(0,7):\n    scaled_test = scaled_test.rename(columns={i:scaler.feature_names_in_[i]})\n\ncopy_test = test.drop(scaler.feature_names_in_,axis=1).copy()\ntest_final = pd.concat((scaled_test, copy_test), axis=1)\n\ntrain_final.Age.describe()","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:04.144045Z","iopub.execute_input":"2022-10-14T01:38:04.144544Z","iopub.status.idle":"2022-10-14T01:38:04.215728Z","shell.execute_reply.started":"2022-10-14T01:38:04.144462Z","shell.execute_reply":"2022-10-14T01:38:04.214578Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"count    8.693000e+03\nmean    -2.125171e-17\nstd      1.000058e+00\nmin     -2.007610e+00\n25%     -6.129662e-01\n50%     -1.248409e-01\n75%      5.724810e-01\nmax      3.501233e+00\nName: Age, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"kfold= KFold(n_splits=10,random_state=42,shuffle=True, ) #kfold cross validation, 10-subsets\nX_train, X_test, y_train, y_test = train_test_split(train_final, target, test_size=0.15,random_state=17, )\nX_train = torch.tensor(X_train.to_numpy()).float(); X_train.shape\ny_train = torch.tensor(y_train.to_numpy()).view(-1,1).float(); y_train.shape\nX_test = torch.tensor(X_test.to_numpy()).float(); X_test.shape\nprint(X_test)\ny_test = torch.tensor(y_test.to_numpy()).view(-1,1).float(); y_test.shape\n\nmodel = nn.Sequential(nn.Linear(31,992),\n                      nn.ReLU(),\n                      nn.Linear(992,496),\n                      nn.ReLU(),\n                      nn.Linear(496,248),\n                      nn.ReLU(),\n                      nn.Linear(248,124),\n                      nn.ReLU(),\n                      nn.Linear(124,1),\n                      nn.Sigmoid())\n                      \n\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.95)\naccuracy_score(y_test.cpu(), (model(X_test).cpu().data.numpy() > 0.5))\naccuracy_min = 0\n\nfor e in range(150):    \n    model.train()\n    counter = 0\n    for i in range(0,116):\n        if counter != 7360:\n            counter += 64\n            X_batch = X_train[counter-64:counter]\n            y_batch = y_train[counter-64:counter].view(-1,1)\n            optimizer.zero_grad()\n            output = model(X_batch)\n            loss = criterion(output, y_batch)\n            loss.backward()\n            optimizer.step()\n        elif counter == 7360:\n            counter += 29\n            X_batch = X_train[counter-29:counter]\n            y_batch = y_train[counter-29:counter].view(-1,1)\n            optimizer.zero_grad()\n            output = model(X_batch)\n            loss = criterion(output, y_batch)\n            loss.backward()\n            optimizer.step()\n    model.eval()\n    loss = criterion(model(X_test), y_test)\n    accuracy_ = accuracy_score(y_test.cpu(), (model(X_test).cpu().data.numpy() > 0.5))\n    print(f\"training loss of {e}th epoch number: {loss}, accuracy: {accuracy_}\")\n    if accuracy_ >= accuracy_min:\n        print('Accuracy metrics increased ({:.6f} --> {:.6f}).  Saving model ...'.format(accuracy_min,accuracy_))\n        torch.save(model.state_dict(), '/kaggle/working/model_space.pt')\n        accuracy_min = accuracy_\nmodel.load_state_dict(torch.load('/kaggle/working/model_space.pt'))\naccuracy_score(y_test.cpu(), (model(X_test).cpu().data.numpy() > 0.5))","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:38:04.217434Z","iopub.execute_input":"2022-10-14T01:38:04.217876Z","iopub.status.idle":"2022-10-14T01:39:48.970560Z","shell.execute_reply.started":"2022-10-14T01:38:04.217840Z","shell.execute_reply":"2022-10-14T01:39:48.969267Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"tensor([[ 1.4093, -0.3331, -0.2810,  ...,  0.0000,  0.0000,  1.0000],\n        [-0.4735, -0.3331, -0.2704,  ...,  0.0000,  0.0000,  1.0000],\n        [-0.9616, -0.3331, -0.2810,  ...,  0.0000,  0.0000,  1.0000],\n        ...,\n        [-0.1248, -0.3331,  0.2573,  ...,  0.0000,  0.0000,  1.0000],\n        [-0.4038, -0.2892, -0.2597,  ...,  0.0000,  0.0000,  1.0000],\n        [ 0.0146, -0.3331, -0.2810,  ...,  0.0000,  0.0000,  1.0000]])\ntraining loss of 0th epoch number: 0.6894974708557129, accuracy: 0.6104294478527608\nAccuracy metrics increased (0.000000 --> 0.610429).  Saving model ...\ntraining loss of 1th epoch number: 0.6827245354652405, accuracy: 0.7615030674846626\nAccuracy metrics increased (0.610429 --> 0.761503).  Saving model ...\ntraining loss of 2th epoch number: 0.6683590412139893, accuracy: 0.7615030674846626\nAccuracy metrics increased (0.761503 --> 0.761503).  Saving model ...\ntraining loss of 3th epoch number: 0.6315164566040039, accuracy: 0.7684049079754601\nAccuracy metrics increased (0.761503 --> 0.768405).  Saving model ...\ntraining loss of 4th epoch number: 0.5407296419143677, accuracy: 0.7822085889570553\nAccuracy metrics increased (0.768405 --> 0.782209).  Saving model ...\ntraining loss of 5th epoch number: 0.4597000777721405, accuracy: 0.7875766871165644\nAccuracy metrics increased (0.782209 --> 0.787577).  Saving model ...\ntraining loss of 6th epoch number: 0.4400721788406372, accuracy: 0.7952453987730062\nAccuracy metrics increased (0.787577 --> 0.795245).  Saving model ...\ntraining loss of 7th epoch number: 0.42903274297714233, accuracy: 0.7960122699386503\nAccuracy metrics increased (0.795245 --> 0.796012).  Saving model ...\ntraining loss of 8th epoch number: 0.4211793541908264, accuracy: 0.7960122699386503\nAccuracy metrics increased (0.796012 --> 0.796012).  Saving model ...\ntraining loss of 9th epoch number: 0.4153866469860077, accuracy: 0.7929447852760736\ntraining loss of 10th epoch number: 0.41076186299324036, accuracy: 0.7952453987730062\ntraining loss of 11th epoch number: 0.40714824199676514, accuracy: 0.7983128834355828\nAccuracy metrics increased (0.796012 --> 0.798313).  Saving model ...\ntraining loss of 12th epoch number: 0.4042522609233856, accuracy: 0.8013803680981595\nAccuracy metrics increased (0.798313 --> 0.801380).  Saving model ...\ntraining loss of 13th epoch number: 0.4020073413848877, accuracy: 0.8044478527607362\nAccuracy metrics increased (0.801380 --> 0.804448).  Saving model ...\ntraining loss of 14th epoch number: 0.4002915918827057, accuracy: 0.803680981595092\ntraining loss of 15th epoch number: 0.39902210235595703, accuracy: 0.8059815950920245\nAccuracy metrics increased (0.804448 --> 0.805982).  Saving model ...\ntraining loss of 16th epoch number: 0.3980768918991089, accuracy: 0.8105828220858896\nAccuracy metrics increased (0.805982 --> 0.810583).  Saving model ...\ntraining loss of 17th epoch number: 0.3974398672580719, accuracy: 0.8144171779141104\nAccuracy metrics increased (0.810583 --> 0.814417).  Saving model ...\ntraining loss of 18th epoch number: 0.3970552682876587, accuracy: 0.8151840490797546\nAccuracy metrics increased (0.814417 --> 0.815184).  Saving model ...\ntraining loss of 19th epoch number: 0.39699745178222656, accuracy: 0.8151840490797546\nAccuracy metrics increased (0.815184 --> 0.815184).  Saving model ...\ntraining loss of 20th epoch number: 0.3968536853790283, accuracy: 0.8151840490797546\nAccuracy metrics increased (0.815184 --> 0.815184).  Saving model ...\ntraining loss of 21th epoch number: 0.39701417088508606, accuracy: 0.8159509202453987\nAccuracy metrics increased (0.815184 --> 0.815951).  Saving model ...\ntraining loss of 22th epoch number: 0.3971383571624756, accuracy: 0.8151840490797546\ntraining loss of 23th epoch number: 0.39752838015556335, accuracy: 0.8144171779141104\ntraining loss of 24th epoch number: 0.39784976840019226, accuracy: 0.8113496932515337\ntraining loss of 25th epoch number: 0.3980335593223572, accuracy: 0.8098159509202454\ntraining loss of 26th epoch number: 0.39831778407096863, accuracy: 0.8090490797546013\ntraining loss of 27th epoch number: 0.39857086539268494, accuracy: 0.8098159509202454\ntraining loss of 28th epoch number: 0.39882513880729675, accuracy: 0.8098159509202454\ntraining loss of 29th epoch number: 0.39899787306785583, accuracy: 0.8105828220858896\ntraining loss of 30th epoch number: 0.3990316689014435, accuracy: 0.8113496932515337\ntraining loss of 31th epoch number: 0.3992308974266052, accuracy: 0.8113496932515337\ntraining loss of 32th epoch number: 0.3992161154747009, accuracy: 0.808282208588957\ntraining loss of 33th epoch number: 0.39906853437423706, accuracy: 0.8090490797546013\ntraining loss of 34th epoch number: 0.3989793658256531, accuracy: 0.8090490797546013\ntraining loss of 35th epoch number: 0.39883899688720703, accuracy: 0.8090490797546013\ntraining loss of 36th epoch number: 0.3985465168952942, accuracy: 0.808282208588957\ntraining loss of 37th epoch number: 0.39831307530403137, accuracy: 0.8052147239263804\ntraining loss of 38th epoch number: 0.3980739116668701, accuracy: 0.8029141104294478\ntraining loss of 39th epoch number: 0.3977954089641571, accuracy: 0.803680981595092\ntraining loss of 40th epoch number: 0.3977225720882416, accuracy: 0.8006134969325154\ntraining loss of 41th epoch number: 0.39765167236328125, accuracy: 0.8029141104294478\ntraining loss of 42th epoch number: 0.3976454436779022, accuracy: 0.8067484662576687\ntraining loss of 43th epoch number: 0.3975732624530792, accuracy: 0.8090490797546013\ntraining loss of 44th epoch number: 0.39756864309310913, accuracy: 0.8090490797546013\ntraining loss of 45th epoch number: 0.3977311849594116, accuracy: 0.8128834355828221\ntraining loss of 46th epoch number: 0.3978131413459778, accuracy: 0.8128834355828221\ntraining loss of 47th epoch number: 0.3982319235801697, accuracy: 0.8144171779141104\ntraining loss of 48th epoch number: 0.39845365285873413, accuracy: 0.8144171779141104\ntraining loss of 49th epoch number: 0.3987214267253876, accuracy: 0.8151840490797546\ntraining loss of 50th epoch number: 0.39892297983169556, accuracy: 0.816717791411043\nAccuracy metrics increased (0.815951 --> 0.816718).  Saving model ...\ntraining loss of 51th epoch number: 0.399106502532959, accuracy: 0.8159509202453987\ntraining loss of 52th epoch number: 0.3992902636528015, accuracy: 0.8174846625766872\nAccuracy metrics increased (0.816718 --> 0.817485).  Saving model ...\ntraining loss of 53th epoch number: 0.39934054017066956, accuracy: 0.8174846625766872\nAccuracy metrics increased (0.817485 --> 0.817485).  Saving model ...\ntraining loss of 54th epoch number: 0.3997686803340912, accuracy: 0.816717791411043\ntraining loss of 55th epoch number: 0.3999427855014801, accuracy: 0.8144171779141104\ntraining loss of 56th epoch number: 0.4001725912094116, accuracy: 0.8136503067484663\ntraining loss of 57th epoch number: 0.4002557396888733, accuracy: 0.8121165644171779\ntraining loss of 58th epoch number: 0.40035393834114075, accuracy: 0.8121165644171779\ntraining loss of 59th epoch number: 0.40067267417907715, accuracy: 0.8105828220858896\ntraining loss of 60th epoch number: 0.40089619159698486, accuracy: 0.8105828220858896\ntraining loss of 61th epoch number: 0.40112027525901794, accuracy: 0.8113496932515337\ntraining loss of 62th epoch number: 0.4014045000076294, accuracy: 0.8113496932515337\ntraining loss of 63th epoch number: 0.4015732705593109, accuracy: 0.8105828220858896\ntraining loss of 64th epoch number: 0.40183117985725403, accuracy: 0.8105828220858896\ntraining loss of 65th epoch number: 0.40202921628952026, accuracy: 0.8105828220858896\ntraining loss of 66th epoch number: 0.40205997228622437, accuracy: 0.8121165644171779\ntraining loss of 67th epoch number: 0.4024190604686737, accuracy: 0.8113496932515337\ntraining loss of 68th epoch number: 0.40249595046043396, accuracy: 0.8105828220858896\ntraining loss of 69th epoch number: 0.40274783968925476, accuracy: 0.8098159509202454\ntraining loss of 70th epoch number: 0.4028286933898926, accuracy: 0.8105828220858896\ntraining loss of 71th epoch number: 0.4029427766799927, accuracy: 0.8105828220858896\ntraining loss of 72th epoch number: 0.4032162129878998, accuracy: 0.8098159509202454\ntraining loss of 73th epoch number: 0.4033142328262329, accuracy: 0.8090490797546013\ntraining loss of 74th epoch number: 0.40371599793434143, accuracy: 0.8098159509202454\ntraining loss of 75th epoch number: 0.4036901891231537, accuracy: 0.8098159509202454\ntraining loss of 76th epoch number: 0.404161661863327, accuracy: 0.8098159509202454\ntraining loss of 77th epoch number: 0.4044231176376343, accuracy: 0.8098159509202454\ntraining loss of 78th epoch number: 0.4046277105808258, accuracy: 0.8121165644171779\ntraining loss of 79th epoch number: 0.4051078259944916, accuracy: 0.8113496932515337\ntraining loss of 80th epoch number: 0.40552544593811035, accuracy: 0.8098159509202454\ntraining loss of 81th epoch number: 0.40594586730003357, accuracy: 0.8105828220858896\ntraining loss of 82th epoch number: 0.40637460350990295, accuracy: 0.8090490797546013\ntraining loss of 83th epoch number: 0.40655696392059326, accuracy: 0.8113496932515337\ntraining loss of 84th epoch number: 0.40738925337791443, accuracy: 0.8105828220858896\ntraining loss of 85th epoch number: 0.40723279118537903, accuracy: 0.8121165644171779\ntraining loss of 86th epoch number: 0.40812861919403076, accuracy: 0.8121165644171779\ntraining loss of 87th epoch number: 0.4088922142982483, accuracy: 0.8105828220858896\ntraining loss of 88th epoch number: 0.409543514251709, accuracy: 0.808282208588957\ntraining loss of 89th epoch number: 0.41045618057250977, accuracy: 0.8075153374233128\ntraining loss of 90th epoch number: 0.4110817611217499, accuracy: 0.8075153374233128\ntraining loss of 91th epoch number: 0.4119812548160553, accuracy: 0.8075153374233128\ntraining loss of 92th epoch number: 0.41276803612709045, accuracy: 0.8044478527607362\ntraining loss of 93th epoch number: 0.41341307759284973, accuracy: 0.8029141104294478\ntraining loss of 94th epoch number: 0.4140951633453369, accuracy: 0.8059815950920245\ntraining loss of 95th epoch number: 0.4148789346218109, accuracy: 0.803680981595092\ntraining loss of 96th epoch number: 0.4158765971660614, accuracy: 0.8067484662576687\ntraining loss of 97th epoch number: 0.4165324568748474, accuracy: 0.8044478527607362\ntraining loss of 98th epoch number: 0.41775232553482056, accuracy: 0.8059815950920245\ntraining loss of 99th epoch number: 0.41891881823539734, accuracy: 0.803680981595092\ntraining loss of 100th epoch number: 0.4201235771179199, accuracy: 0.8052147239263804\ntraining loss of 101th epoch number: 0.4210101068019867, accuracy: 0.8044478527607362\ntraining loss of 102th epoch number: 0.4221731126308441, accuracy: 0.8029141104294478\ntraining loss of 103th epoch number: 0.4235560894012451, accuracy: 0.8044478527607362\ntraining loss of 104th epoch number: 0.424146443605423, accuracy: 0.8013803680981595\ntraining loss of 105th epoch number: 0.4250754117965698, accuracy: 0.8044478527607362\ntraining loss of 106th epoch number: 0.42495015263557434, accuracy: 0.803680981595092\ntraining loss of 107th epoch number: 0.42565852403640747, accuracy: 0.8006134969325154\ntraining loss of 108th epoch number: 0.4266844689846039, accuracy: 0.8021472392638037\ntraining loss of 109th epoch number: 0.4279455542564392, accuracy: 0.8013803680981595\ntraining loss of 110th epoch number: 0.42894965410232544, accuracy: 0.8013803680981595\ntraining loss of 111th epoch number: 0.4298790395259857, accuracy: 0.799079754601227\ntraining loss of 112th epoch number: 0.43182888627052307, accuracy: 0.7967791411042945\ntraining loss of 113th epoch number: 0.4326801002025604, accuracy: 0.7975460122699386\ntraining loss of 114th epoch number: 0.4344119131565094, accuracy: 0.7983128834355828\ntraining loss of 115th epoch number: 0.4360080063343048, accuracy: 0.7983128834355828\ntraining loss of 116th epoch number: 0.43716293573379517, accuracy: 0.7960122699386503\ntraining loss of 117th epoch number: 0.43949422240257263, accuracy: 0.7929447852760736\ntraining loss of 118th epoch number: 0.44060632586479187, accuracy: 0.7937116564417178\ntraining loss of 119th epoch number: 0.44202274084091187, accuracy: 0.7921779141104295\ntraining loss of 120th epoch number: 0.4435634911060333, accuracy: 0.7944785276073619\ntraining loss of 121th epoch number: 0.4459102153778076, accuracy: 0.7952453987730062\ntraining loss of 122th epoch number: 0.4479825496673584, accuracy: 0.7921779141104295\ntraining loss of 123th epoch number: 0.4496212899684906, accuracy: 0.7921779141104295\ntraining loss of 124th epoch number: 0.45200657844543457, accuracy: 0.7914110429447853\ntraining loss of 125th epoch number: 0.45379096269607544, accuracy: 0.7937116564417178\ntraining loss of 126th epoch number: 0.4562705159187317, accuracy: 0.7921779141104295\ntraining loss of 127th epoch number: 0.45752906799316406, accuracy: 0.7929447852760736\ntraining loss of 128th epoch number: 0.45983821153640747, accuracy: 0.7921779141104295\ntraining loss of 129th epoch number: 0.45998695492744446, accuracy: 0.7898773006134969\ntraining loss of 130th epoch number: 0.46179628372192383, accuracy: 0.7906441717791411\ntraining loss of 131th epoch number: 0.4638335704803467, accuracy: 0.7914110429447853\ntraining loss of 132th epoch number: 0.46528804302215576, accuracy: 0.7914110429447853\ntraining loss of 133th epoch number: 0.4666415750980377, accuracy: 0.7906441717791411\ntraining loss of 134th epoch number: 0.46764421463012695, accuracy: 0.7906441717791411\ntraining loss of 135th epoch number: 0.46896591782569885, accuracy: 0.7883435582822086\ntraining loss of 136th epoch number: 0.4699173867702484, accuracy: 0.7883435582822086\ntraining loss of 137th epoch number: 0.47148993611335754, accuracy: 0.7875766871165644\ntraining loss of 138th epoch number: 0.4742087721824646, accuracy: 0.7891104294478528\ntraining loss of 139th epoch number: 0.4750930666923523, accuracy: 0.7914110429447853\ntraining loss of 140th epoch number: 0.4764806032180786, accuracy: 0.7906441717791411\ntraining loss of 141th epoch number: 0.4763500988483429, accuracy: 0.7914110429447853\ntraining loss of 142th epoch number: 0.4778478443622589, accuracy: 0.7929447852760736\ntraining loss of 143th epoch number: 0.4784756004810333, accuracy: 0.7983128834355828\ntraining loss of 144th epoch number: 0.48037201166152954, accuracy: 0.799079754601227\ntraining loss of 145th epoch number: 0.48673561215400696, accuracy: 0.7937116564417178\ntraining loss of 146th epoch number: 0.5184832811355591, accuracy: 0.781441717791411\ntraining loss of 147th epoch number: 0.46131476759910583, accuracy: 0.8136503067484663\ntraining loss of 148th epoch number: 0.45197099447250366, accuracy: 0.7975460122699386\ntraining loss of 149th epoch number: 0.45802372694015503, accuracy: 0.7983128834355828\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.8174846625766872"},"metadata":{}}]},{"cell_type":"code","source":"predictions = torch.tensor(test_final.to_numpy()).float(); predictions.shape\npredictions = (model(predictions).cpu().detach().numpy() > 0.5)\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:39:48.972831Z","iopub.execute_input":"2022-10-14T01:39:48.973702Z","iopub.status.idle":"2022-10-14T01:39:49.051531Z","shell.execute_reply.started":"2022-10-14T01:39:48.973651Z","shell.execute_reply":"2022-10-14T01:39:49.050119Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(4277, 1)"},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:39:49.056164Z","iopub.execute_input":"2022-10-14T01:39:49.056863Z","iopub.status.idle":"2022-10-14T01:39:49.064848Z","shell.execute_reply.started":"2022-10-14T01:39:49.056813Z","shell.execute_reply":"2022-10-14T01:39:49.063769Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[ True],\n       [False],\n       [ True],\n       ...,\n       [ True],\n       [ True],\n       [ True]])"},"metadata":{}}]}]}